{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKscxQWcoX-u"
      },
      "source": [
        "# Introduction to Bias-Variance Tradeoff through Logistic Regression\n",
        "\n",
        "\n",
        "Welcome to our practical session on logistic regression, where we'll explore the critical concept of the bias-variance tradeoff in machine learning. Models with high bias oversimplify reality and tend to underperform, while models with high variance capture too much noise, leading to overfitting. Through logistic regression and the application of regularization techniques, we'll learn how to balance bias and variance, optimizing our models for better accuracy on unseen data. Let's dive into this fundamental balance to enhance our machine learning skills."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHnPso89qdf4"
      },
      "source": [
        "In this practical session, we will be working with a dataset that provides historical records of water level changes and the corresponding flow of water from a dam. The data is represented through two key variables: x for the change in water level and y for the amount of water flowing out of the dam.\n",
        "\n",
        "Our dataset is thoughtfully partitioned into three distinct subsets to facilitate a comprehensive learning experience:\n",
        "\n",
        "**Training Set (X, y)**: This is the primary dataset upon which your model will train. It includes various instances of water level changes and the corresponding flow measurements, allowing the model to learn the underlying patterns.\n",
        "\n",
        "**Cross Validation Set (Xval, yval)**: This subset is crucial for fine-tuning the model's regularization parameter. It helps determine the optimal balance between bias and variance, ensuring the model generalizes well to new, unseen data.\n",
        "\n",
        "**Test Set (Xtest, ytest)**: Comprising data that the model has never encountered during its training phase, this set is essential for evaluating the final performance of your model. It offers a clear picture of how well the model can predict water flow from new water level changes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooTeBUQwqyt4"
      },
      "source": [
        "Load the dataset using `scipy.io`, `loadmat` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJxfhpyKrR6x"
      },
      "source": [
        "Display the key of the dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CScIkfxGrWoV"
      },
      "source": [
        "Now extract, data for train / validation / test\n",
        "\n",
        "We can call those variables\n",
        "- x_train, y_train\n",
        "- x_val, y_val\n",
        "- x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpVheWGbrjv-"
      },
      "source": [
        "Display the shape of all the variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCqigXQErvl5"
      },
      "source": [
        "Display the samples for train / validation / test on the same plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2C-oSfksD1P"
      },
      "source": [
        "Concatenate our train data with the validation data and test data\n",
        "\n",
        "we don't have enough data to have 3 sets\n",
        "\n",
        "and then use sklearn train test split to split your data into training and test part.\n",
        "\n",
        "you can use 30% of the full dataset for test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P3rXeB1vNhI"
      },
      "source": [
        "### Linear regression with L2 regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbMPezoYspMD"
      },
      "source": [
        "Fit a Ridge regression\n",
        "\n",
        "Reminder of the ridge regression:\n",
        "\n",
        "Ridge regression, also known as L2 regularization, is a technique used to address the issue of multicollinearity in multiple regression models. Multicollinearity occurs when independent variables in a regression model are highly correlated, leading to instability in the estimation of the regression coefficients.\n",
        "\n",
        "In ridge regression, we modify the cost function by adding a penalty equivalent to the square of the magnitude of the coefficients.\n",
        "\n",
        "```\n",
        "||y - Xw||^2_2 + alpha * ||w||^2_2\n",
        "```\n",
        "\n",
        "Look at the document of sklearn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZ9fcCmstvAB"
      },
      "source": [
        "Create a function that is going to plot the training and the line of the linear regression (with L2 regularization)\n",
        "\n",
        "The most simple approach to plot the line is to give 2 data points as input of our model and then get both predictions. Then you can call, with matplotlib\n",
        "\n",
        "```\n",
        "plt.plot(x_data, y_pred, 'b--', label='Prediction')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dagydJjavAsS"
      },
      "source": [
        "Now compute the score on the train and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMG6vrQOvR9i"
      },
      "source": [
        "### Polynomial regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgdeX4K4vudJ"
      },
      "source": [
        "To simulate the polynomial regression we can use the polynomial features\n",
        "\n",
        "Fit the Ridge regression with first:\n",
        "\n",
        "- `PolynomialFeatures`\n",
        "\n",
        "- `StandardScaler`\n",
        "\n",
        "\n",
        "Use `alpha` = 0.001\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47Gq8X0WwX94"
      },
      "source": [
        "Now we want to plot our results\n",
        "\n",
        "Use linspace to generate a set of x on which we will apply our prediction\n",
        "\n",
        "we will use those x with our y predictions and plot function from matplotlib to plot the curve.\n",
        "\n",
        "Plot for both training and test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF8M9oUHxA5J"
      },
      "source": [
        "We should see some overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWv_JwkbxNtO"
      },
      "source": [
        "now use `alpha` = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpJDWOea0Hg_"
      },
      "source": [
        "Display the train / test score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUGaRasPznI4"
      },
      "source": [
        "Now let's try to increase the alpha parameter to 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIiUPTmjz-ly"
      },
      "source": [
        "display the model score for training and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
